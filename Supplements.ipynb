{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c443d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.9196 - root_mean_squared_error: 0.9588 - val_loss: 1.5229 - val_root_mean_squared_error: 1.2340\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8861 - root_mean_squared_error: 0.9413 - val_loss: 1.5493 - val_root_mean_squared_error: 1.2447\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8793 - root_mean_squared_error: 0.9376 - val_loss: 1.5354 - val_root_mean_squared_error: 1.2391\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8516 - root_mean_squared_error: 0.9228 - val_loss: 1.5357 - val_root_mean_squared_error: 1.2392\n",
      "Model training completed.\n",
      "Training Loss History: [0.8837652206420898, 0.8801397085189819, 0.8713476061820984, 0.863332211971283]\n",
      "Validation Root Mean Squared Error: [1.234045386314392, 1.244708776473999, 1.2391114234924316, 1.2392209768295288]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Multiply, Conv1D, MaxPooling1D, Flatten, Dense, ReLU, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('food_supplements.csv')\n",
    "df['Sold_date'] = pd.to_datetime(df['Sold_date'], format='%m/%d/%y')\n",
    "df.set_index('Sold_date', inplace=True)\n",
    "daily_data = df.pivot_table(values='Sold_quantity', index='Sold_date', columns='Product_details', aggfunc='sum').fillna(0)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "daily_data_scaled = scaler.fit_transform(daily_data)\n",
    "daily_data_scaled = pd.DataFrame(daily_data_scaled, index=daily_data.index, columns=daily_data.columns)\n",
    "\n",
    "# Prepare sequences\n",
    "sequence_length = 14\n",
    "prediction_length = 7\n",
    "num_features = daily_data_scaled.shape[1]\n",
    "\n",
    "def create_sequences(data, sequence_length, prediction_length):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - sequence_length - prediction_length + 1):\n",
    "        x.append(data.iloc[i:(i + sequence_length)].values)\n",
    "        y.append(data.iloc[i + sequence_length:(i + sequence_length + prediction_length)].values)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_lstm, y_lstm = create_sequences(daily_data_scaled, sequence_length, prediction_length)\n",
    "\n",
    "# Define the model building function\n",
    "def build_model(num_features):\n",
    "    input_layer = Input(shape=(sequence_length, num_features))\n",
    "    lstm1 = LSTM(20, return_sequences=True)(input_layer)\n",
    "    lstm2 = LSTM(20, return_sequences=True)(input_layer)\n",
    "    combined_features = Multiply()([lstm1, lstm2])\n",
    "\n",
    "    conv1 = Conv1D(64, 3, activation='relu')(combined_features)\n",
    "    max_pool = MaxPooling1D(2)(conv1)\n",
    "    conv2 = Conv1D(64, 3, activation='relu')(max_pool)\n",
    "    flat = Flatten()(conv2)\n",
    "\n",
    "    num_output_units = prediction_length * num_features\n",
    "    dense = Dense(num_output_units)(flat)\n",
    "    output_layer = Reshape((prediction_length, num_features))(dense)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "model = build_model(num_features)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Model training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(x_lstm, y_lstm, validation_split=0.2, epochs=100, batch_size=64, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Output training results\n",
    "print(\"Model training completed.\")\n",
    "print(\"Training Loss History:\", history.history['loss'])\n",
    "print(\"Validation Root Mean Squared Error:\", history.history['val_root_mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430ad22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
